{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv('Cleaned-P&P data.csv')\n",
    "\n",
    "blanks = []  # start with an empty list`\n",
    "\n",
    "for i,c,d,inc,sd in df1.itertuples():  # iterate over the DataFrame\n",
    "        if c == 'O' or c=='E':         # test 'review' for whitespace\n",
    "            blanks.append(i)     # add matching index numbers to the list\n",
    "df1.drop(blanks, inplace=True)\n",
    "df1[\"desc\"] = df1[\"short_des\"] + '. ' + df1[\"desc\"]\n",
    "df1.reset_index(drop=True,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df2 = pd.read_csv('Cleaned-P&P data.csv')\n",
    "blanks2 = []  # start with an empty list`\n",
    "\n",
    "for i,c,d,inc,sd in df2.itertuples():  # iterate over the DataFrame\n",
    "        if c == 'O' or c=='E':         # test 'review' for whitespace\n",
    "            blanks2.append(i)     # add matching index numbers to the list\n",
    "df2.drop(blanks2, inplace=True)\n",
    "df2.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([df1, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the texts\n",
    "import re\n",
    "corpus = []\n",
    "all_words = []\n",
    "max_len=0\n",
    "for i in range(0, 488):\n",
    "\n",
    "    review = re.sub('\\w\\d{7}', ' ', dataset['desc'][i])\n",
    "    review = re.sub('[^a-zA-Z]', ' ', review)\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = ' '.join(review)\n",
    "    \n",
    "    review = nlp(review)\n",
    "    review = [word.text for word in review]\n",
    "   # for word.text in review:\n",
    "        \n",
    "    all_words.append(review) \n",
    "    if len(review) > max_len:\n",
    "        max_len = len(review)\n",
    "    ds = ' '.join(review)\n",
    "#    for word2vec we want an array of vectors\n",
    "    corpus.append(ds)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardise key terms in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpf = pd.read_csv('Del-Pass.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     delivery subscription service\n",
       "1        delivery pass subscription\n",
       "2             delivery pass service\n",
       "3                free delivery pass\n",
       "4                   delivery passes\n",
       "5                    delivery pass \n",
       "6        p&p delivery subscription \n",
       "7            delivery subscriptions\n",
       "8             delivery subscription\n",
       "9                      delivery sub\n",
       "10                      p&p service\n",
       "11                              p&p\n",
       "12                     subscription\n",
       "Name: kpattern, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpf['kpattern']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_list = dpf['kpattern'].tolist()\n",
    "regex = re.compile(r'(' + '|'.join(keys_list) + r')') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cus_list = ['remove','removed','cancelled', 'cancel' ,'deleted']\n",
    "regey = re.compile(r'(' + '|'.join(cus_list) + r')') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords=nltk.corpus.stopwords.words('english')\n",
    "additional =[\"thank you\",\"please\",\"hello\",\"hi\",\"advise\",\"hin't\",\"st\",\"nd\",\"rd\",\"th\",\"thank\"]\n",
    "stopwords = stopwords + additional\n",
    "remov=[]\n",
    "for ele in stopwords:\n",
    "    matches = re.findall(\"n't\",ele)\n",
    "    matches2 = re.findall(\"'nt\",ele)\n",
    "    if len(matches)>0 or len(matches2)>0:\n",
    "        remov.append(ele)\n",
    "stopwords = [word for word in stopwords if word not in remov]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cldict = {'P':1 , 'R':0}\n",
    "dataset['Class Label'] = dataset['class'].map(cldict)\n",
    "label_series = pd.Series(dataset['Class Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(488,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "class_label = np.array(label_series)\n",
    "y = class_label\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=47)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create custom rules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#segment_featurizer = SegmentFeaturizer()  # more on this below\n",
    "class CustomLinguisticFeatureTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass   \n",
    "  #  def fit(self, X, y=None):\n",
    "    def fit(self, X, y):\n",
    "        return self    \n",
    "    def transform(self, X):       \n",
    "        ref_corpus=[]\n",
    "        for text in X:           \n",
    "            trans = regex.sub(lambda m: m.group().replace(m.group(),\"del-pass\"),text)\n",
    "            trans_ref = regey.sub(lambda n: n.group().replace(n.group(),\"delete\"),trans)\n",
    "             \n",
    "            ref_corpus.append(trans_ref)\n",
    "       \n",
    "        return ref_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy Vector Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class SpacyVectorTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, nlp):\n",
    "        self.nlp = nlp\n",
    "        self.dim = 300\n",
    "        pass\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Doc.vector defaults to an average of the token vectors.\n",
    "        # https://spacy.io/api/doc#vector\n",
    "        lemmatized_list=[]\n",
    "        for snt in X:\n",
    "        #    print(snt)\n",
    "            tokens = nlp(snt)\n",
    "        #    for token in tokenized:\n",
    "            filtered_sentence = [w.text for w in tokens if not w.text in stopwords]\n",
    "        #                 lemm = token.lemma_ for token.text in token\n",
    "        #             lemmatized_list.append(lemm)\n",
    "            stri = ' '.join(filtered_sentence)\n",
    "            lemmatized_list.append(stri)\n",
    "        return [self.nlp(text).vector for text in lemmatized_list]\n",
    "       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AVNEET\\miniconda3\\envs\\nlp_course\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('mean_embeddings', SpacyVectorTransformer(nlp=<spacy.lang.en.English object at 0x0000029F648E8B08>)), ('reduce_dim', TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
       "       random_state=None, tol=0.0)), ('classifier', RandomForestClassifier(bootstrap=True, class_weight=None, c...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "embeddings_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"mean_embeddings\", SpacyVectorTransformer(nlp)),\n",
    "        (\"reduce_dim\", TruncatedSVD(50)),\n",
    "        (\"classifier\", RandomForestClassifier()),\n",
    "    ]\n",
    ")\n",
    "embeddings_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-afd932bfeb95>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m embeddings_pipeline2 = Pipeline(\n\u001b[0m\u001b[0;32m      5\u001b[0m     steps=[\n\u001b[0;32m      6\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[1;34m\"mean_embeddings\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSpacyVectorTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "embeddings_pipeline2 = Pipeline(\n",
    "    steps=[\n",
    "        (\"mean_embeddings\", SpacyVectorTransformer(nlp)),\n",
    "        (\"reduce_dim\", TruncatedSVD(50)),\n",
    "        (\"classifier\", LinearSVC()),\n",
    "    ]\n",
    ")\n",
    "embeddings_pipeline2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "svm = LinearSVC()\n",
    "embeddings_pipeline3 = Pipeline(\n",
    "    steps=[\n",
    "        (\"mean_embeddings\", SpacyVectorTransformer(nlp)),\n",
    "        (\"reduce_dim\", TruncatedSVD(50)),\n",
    "        (\"classifier\", CalibratedClassifierCV(svm)),\n",
    "    ]\n",
    ")\n",
    "embeddings_pipeline3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AVNEET\\miniconda3\\envs\\nlp_course\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('cust', CustomLinguisticFeatureTransformer()), ('mean_embeddings', SpacyVectorTransformer(nlp=<spacy.lang.en.English object at 0x0000029F648E8B08>)), ('reduce_dim', TruncatedSVD(algorithm='randomized', n_components=200, n_iter=5,\n",
       "       random_state=None, tol=0.0)), ('classifier', Calibrated...lty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "            cv='warn', method='sigmoid'))])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "svm = LinearSVC()\n",
    "embeddings_pipeline4 = Pipeline(\n",
    "    steps=[\n",
    "        (\"cust\",CustomLinguisticFeatureTransformer()),\n",
    "#        (\"tfidf\", TfidfVectorizer()),\n",
    "        (\"mean_embeddings\", SpacyVectorTransformer(nlp)),\n",
    "        (\"reduce_dim\", TruncatedSVD(200)),\n",
    "#         (\"dict_vect\", DictVectorizer()),\n",
    "        (\"classifier\", CalibratedClassifierCV(svm)),\n",
    "    ]\n",
    ")\n",
    "embeddings_pipeline4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('cust', CustomLinguisticFeatureTransformer()), ('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1)...rue,\n",
       "        vocabulary=None)), ('mnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#svm = LinearSVC()\n",
    "embeddings_pipeline5 = Pipeline(\n",
    "    steps=[\n",
    "        (\"cust\",CustomLinguisticFeatureTransformer()),\n",
    "       (\"tfidf\", TfidfVectorizer()),\n",
    "#        (\"mean_embeddings\", SpacyVectorTransformer(nlp)),\n",
    "#        (\"reduce_dim\", TruncatedSVD(50)),\n",
    "#         (\"dict_vect\", DictVectorizer()),\n",
    "#        (\"rdf\", RandomForestClassifier()),\n",
    "        (\"mnb\",MultinomialNB()),\n",
    "    ]\n",
    ")\n",
    "embeddings_pipeline5.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = embeddings_pipeline4.predict(X_test)\n",
    "cr = classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       1.00      1.00      1.00        65\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        98\n",
      "   macro avg       1.00      1.00      1.00        98\n",
      "weighted avg       1.00      1.00      1.00        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[22.2, 77.8]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1 = [' ']\n",
    "print(embeddings_pipeline4.predict(list1))\n",
    "probs = embeddings_pipeline4.predict_proba(list1)\n",
    "np.around(probs, decimals = 3)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[33,  0],\n",
       "       [ 0, 65]], dtype=int64)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014344262295081968"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 0.97959184, 1.        , 0.93877551,\n",
       "       1.        , 1.        , 0.97959184, 1.        , 0.91666667])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(embeddings_pipeline5, X, y, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_mean_score = np.mean(cross_val_score(embeddings_pipeline3, X, y, cv = 10))\n",
    "clf_score = embeddings_pipeline3.score(X_test, y_test)\n",
    "cv_mean_score, clf_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "488"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = embeddings_pipeline5.predict(X)\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9959016393442623"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_score = embeddings_pipeline3.score(X, y)\n",
    "clf_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class:pnt work requests hello service line please can you look into the cancel the following account the delivery sub is not working customerno itemno rv fg delivery sub purchase date please if you could reply back and keep us up to date regards ahmed hussain proactive notification team citrix i d managers name claire wrigley Index is : 171\n",
      "predicted class:delivery pass needs removing on staff accounts supra dba req please can the delivery pass be removed from the attached staff accounts thank you Index is : 201\n",
      "predicted class:hello service line please can you look into the cancel the following account the delivery sub is not working customerno itemno rv fg delivery sub purchase date please if you could reply back and keep us up to date regards ahmed hussain proactive notification team citrix i d managers name claire wrigley Index is : 415\n",
      "predicted class:please can you activate the delivery pass on customers account thank you Index is : 435\n",
      "predicted class:please can the delivery pass be removed from the attached staff accounts thank you Index is : 445\n",
      "predicted class:please can you reactivate annual delivery pass on customersaccount thank you Index is : 461\n",
      "predicted class:please can you apply the annual delivery pass on the attached customers account thank you Index is : 466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['pnt work requests hello service line please can you look into the cancel the following account the delivery sub is not working customerno itemno rv fg delivery sub purchase date please if you could reply back and keep us up to date regards ahmed hussain proactive notification team citrix i d managers name claire wrigley',\n",
       "       'delivery pass needs removing on staff accounts supra dba req please can the delivery pass be removed from the attached staff accounts thank you',\n",
       "       'hello service line please can you look into the cancel the following account the delivery sub is not working customerno itemno rv fg delivery sub purchase date please if you could reply back and keep us up to date regards ahmed hussain proactive notification team citrix i d managers name claire wrigley',\n",
       "       'please can you activate the delivery pass on customers account thank you',\n",
       "       'please can the delivery pass be removed from the attached staff accounts thank you',\n",
       "       'please can you reactivate annual delivery pass on customersaccount thank you',\n",
       "       'please can you apply the annual delivery pass on the attached customers account thank you'],\n",
       "      dtype='<U321')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Faulty_Xtest =[]\n",
    "for i in range(0,488):\n",
    "    if y[i] != predictions[i]:\n",
    "        print(f'predicted class:{X[i]}', f'Index is : {i}')\n",
    "        Faulty_Xtest.append(X[i])\n",
    "arr = np.array(Faulty_Xtest)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('INC0612636',\n",
       " 'delivery pass needs removing on staff accounts supra dba req. please can the delivery pass be removed from the attached staff accounts?thank you!',\n",
       " 'P')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['inc_num'][201], dataset['desc'][201], dataset['class'][201]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi           INTJ   intj   interjection\n",
      "the          DET    det    determiner\n",
      "customer     NOUN   nsubj  nominal subject\n",
      "took         VERB   ccomp  clausal complement\n",
      "the          DET    det    determiner\n",
      "delivery     NOUN   compound None\n",
      "subscription NOUN   dobj   direct object\n",
      "out          PART   prt    particle\n",
      "on           ADP    prep   prepositional modifier\n",
      "th           DET    nummod None\n",
      "november     NOUN   pobj   object of preposition\n",
      "but          CCONJ  cc     coordinating conjunction\n",
      "is           VERB   aux    auxiliary\n",
      "still        ADV    advmod adverbial modifier\n",
      "being        VERB   auxpass auxiliary (passive)\n",
      "charged      VERB   conj   conjunct\n",
      "delivey      NOUN   advmod adverbial modifier\n",
      "please       INTJ   intj   interjection\n",
      "advise       VERB   ROOT   None\n",
      "thanks       NOUN   dobj   direct object\n",
      "peter        X      dobj   direct object\n"
     ]
    }
   ],
   "source": [
    "# Enter your code here:\n",
    "\n",
    "for token in nlp(X_test[94]):\n",
    "    print(f'{token.text:{12}} {token.pos_:{6}} {token.dep_:{6}} {spacy.explain(token.dep_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">\n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    annual\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " delivery pass not working please apply delivery pass to account t purchased thanks</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from spacy import displacy\n",
    "displacy.render(nlp(X_test[95]), style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 47)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "for match in re.finditer(\"delivery subscription \",X_test[94]):\n",
    "    X_test[94]\n",
    "    print(match.span())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good afternoon this customer is being charged for delivery after purchasing the subscription please can you see if it needs activating thank you in advance rebecca connolly proactive notification team\n",
      "delivery pass needs removing on staff accounts orders supra dba req please can you remove the delivery pass be removed from the attached staff accounts thanks\n",
      "delivery pass needs removing on staff accounts orders supra dba req please can the delivery pass be removed from the attached staff accounts thanks\n",
      "customer being charged for delivery customer website jd williams mainframe issue she ordered on th april and th mayand she is being charged for delivery even after she has the subscription order number contact number\n",
      "website web shop issues short description tamara called in to report that the customer purchase the delivery subscription on the st of marchbut she is still charged for delivery every time instead of having a delivery subscription affected people\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['good afternoon customer charged delivery purchasing subscription see needs activating thank advance rebecca connolly proactive notification team',\n",
       " 'delivery pass needs removing staff accounts orders supra dba req remove delivery pass removed attached staff accounts thanks',\n",
       " 'delivery pass needs removing staff accounts orders supra dba req delivery pass removed attached staff accounts thanks',\n",
       " 'customer charged delivery customer website jd williams mainframe issue ordered th april th mayand charged delivery even subscription order number contact number',\n",
       " 'website web shop issues short description tamara called report customer purchase delivery subscription st marchbut still charged delivery every time instead delivery subscription affected people']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_list=[]\n",
    "for snt in X[:5]:\n",
    "    print(snt)\n",
    "    tokens = nlp(snt)\n",
    "#    for token in tokenized:\n",
    "    filtered_sentence = [w.text for w in tokens if not w.text in stopwords]\n",
    "#                 lemm = token.lemma_ for token.text in token\n",
    "#             lemmatized_list.append(lemm)\n",
    "    stri = ' '.join(filtered_sentence)\n",
    "    lemmatized_list.append(stri)\n",
    "lemmatized_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 47)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matche = re.findall(\"delivery subscription \",X_test[94])\n",
    "match.span()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo%s bar\n"
     ]
    }
   ],
   "source": [
    "regex = re.compile('([a-zA-Z]\\\"[a-zA-Z])', re.S)\n",
    "myfile =  'foo\"s bar'\n",
    "myfile2 = regex.sub(lambda m: m.group().replace('\"',\"%\",1), myfile)\n",
    "print(myfile2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delivery subscription\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'please can you apply the annual del-pass is activated on this customers account purchased still being charged for delivery thank you'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "lst = ['delivery subscription service', 'delivery pass subscription','delivery pass service','delivery passes','delivery pass ','p&p delivery subscription ','delivery subscriptions','delivery subscription']\n",
    "\n",
    "def replace_double_quote(match):\n",
    "    text = match.group()\n",
    "    print(match.group())\n",
    "    return text.replace(text, 'del-pass')\n",
    "regex = re.compile(r'(' + '|'.join(lst) + r')')\n",
    "myfile = 'please can you apply the annual delivery subscription is activated on this customers account purchased still being charged for delivery thank you'\n",
    "regex.sub(replace_double_quote, myfile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rap\"s rap rap rap\"s rap\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "lst = ['foo', 'bar', 'and']\n",
    "def my_func():\n",
    "    \n",
    "    regex = re.compile(r'(' + '|'.join(lst) + r')')\n",
    "    myfile = 'foo\"s bar and bar\"s foo'\n",
    "   \n",
    "    pxk = regex.sub(lambda m: m.group().replace(m.group(),\"rap\",1), myfile)\n",
    "    return pxk\n",
    "#     def replace_double_quote(match):\n",
    "#         text = match.group()\n",
    "#         print(text)\n",
    "#         return text.replace(text, 'rap')\n",
    "   \n",
    "print(my_func())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delivery sub\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'please can you apply the annual del-passscription is activated on this customers account purchased still being charged for delivery thank you'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def match_kpatterns(match):\n",
    "    \n",
    "    text = match.group()\n",
    "    print(match.group())\n",
    "    return text.replace(text, 'del-pass')\n",
    "\n",
    "\n",
    "regez = re.compile(r'(' + '|'.join(keys_list) + r')')\n",
    "seg = \"please can you apply the annual delivery subscription is activated on this customers account purchased still being charged for delivery thank you\"\n",
    "\n",
    "regez.sub(match_kpatterns, seg)\n",
    "#    return regex.sub(lambda m: m.group().replace(m.group(),\"del-pass\"), rfseg)\n",
    "#r_featurize(seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.536630904249573"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nlp(u'trashbin')\n",
    "text1 = nlp(u'dustbin')\n",
    "fr = text1.similarity(text)\n",
    "fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mathc is : [] 0\n",
      "mathc is : [] 1\n",
      "mathc is : [] 2\n",
      "mathc is : [] 3\n",
      "mathc is : [] 4\n",
      "mathc is : [] 5\n",
      "mathc is : [] 6\n",
      "mathc is : [] 7\n",
      "mathc is : [] 8\n",
      "mathc is : [] 9\n",
      "mathc is : [] 10\n",
      "mathc is : [] 11\n",
      "mathc is : [] 12\n",
      "mathc is : [] 13\n",
      "mathc is : [] 14\n",
      "mathc is : [] 15\n",
      "mathc is : [] 16\n",
      "mathc is : [] 17\n",
      "mathc is : [] 18\n",
      "mathc is : [] 19\n",
      "mathc is : [] 20\n",
      "mathc is : [] 21\n",
      "mathc is : [] 22\n",
      "mathc is : [] 23\n",
      "mathc is : [] 24\n",
      "mathc is : [] 25\n",
      "mathc is : ['n t ', 'n t '] 26\n",
      "mathc is : [] 27\n",
      "mathc is : [] 28\n",
      "mathc is : [] 29\n",
      "mathc is : [] 30\n",
      "mathc is : [] 31\n",
      "mathc is : [] 32\n",
      "mathc is : [] 33\n",
      "mathc is : [] 34\n",
      "mathc is : [] 35\n",
      "mathc is : [] 36\n",
      "mathc is : [] 37\n",
      "mathc is : [] 38\n",
      "mathc is : [] 39\n",
      "mathc is : [] 40\n",
      "mathc is : [] 41\n",
      "mathc is : [] 42\n",
      "mathc is : [] 43\n",
      "mathc is : [] 44\n",
      "mathc is : [] 45\n",
      "mathc is : [] 46\n",
      "mathc is : ['n t '] 47\n",
      "mathc is : [] 48\n",
      "mathc is : [] 49\n",
      "mathc is : [] 50\n",
      "mathc is : [] 51\n",
      "mathc is : [] 52\n",
      "mathc is : [] 53\n",
      "mathc is : [] 54\n",
      "mathc is : ['n t '] 55\n",
      "mathc is : [] 56\n",
      "mathc is : [] 57\n",
      "mathc is : [] 58\n",
      "mathc is : [] 59\n",
      "mathc is : [] 60\n",
      "mathc is : [] 61\n",
      "mathc is : [] 62\n",
      "mathc is : [] 63\n",
      "mathc is : [] 64\n",
      "mathc is : [] 65\n",
      "mathc is : [] 66\n",
      "mathc is : ['n t '] 67\n",
      "mathc is : [] 68\n",
      "mathc is : [] 69\n",
      "mathc is : [] 70\n",
      "mathc is : [] 71\n",
      "mathc is : [] 72\n",
      "mathc is : [] 73\n",
      "mathc is : [] 74\n",
      "mathc is : [] 75\n",
      "mathc is : [] 76\n",
      "mathc is : [] 77\n",
      "mathc is : [] 78\n",
      "mathc is : [] 79\n",
      "mathc is : [] 80\n",
      "mathc is : [] 81\n",
      "mathc is : [] 82\n",
      "mathc is : [] 83\n",
      "mathc is : [] 84\n",
      "mathc is : [] 85\n",
      "mathc is : [] 86\n",
      "mathc is : [] 87\n",
      "mathc is : [] 88\n",
      "mathc is : [] 89\n",
      "mathc is : [] 90\n",
      "mathc is : [] 91\n",
      "mathc is : [] 92\n",
      "mathc is : [] 93\n",
      "mathc is : [] 94\n",
      "mathc is : [] 95\n",
      "mathc is : [] 96\n",
      "mathc is : [] 97\n",
      "mathc is : [] 98\n",
      "mathc is : [] 99\n",
      "mathc is : [] 100\n",
      "mathc is : [] 101\n",
      "mathc is : [] 102\n",
      "mathc is : [] 103\n",
      "mathc is : [] 104\n",
      "mathc is : [] 105\n",
      "mathc is : [] 106\n",
      "mathc is : [] 107\n",
      "mathc is : [] 108\n",
      "mathc is : [] 109\n",
      "mathc is : [] 110\n",
      "mathc is : [] 111\n",
      "mathc is : [] 112\n",
      "mathc is : [] 113\n",
      "mathc is : [] 114\n",
      "mathc is : [] 115\n",
      "mathc is : [] 116\n",
      "mathc is : [] 117\n",
      "mathc is : [] 118\n",
      "mathc is : [] 119\n",
      "mathc is : [] 120\n",
      "mathc is : [] 121\n",
      "mathc is : [] 122\n",
      "mathc is : ['n t '] 123\n",
      "mathc is : [] 124\n",
      "mathc is : [] 125\n",
      "mathc is : [] 126\n",
      "mathc is : [] 127\n",
      "mathc is : [] 128\n",
      "mathc is : [] 129\n",
      "mathc is : [] 130\n",
      "mathc is : [] 131\n",
      "mathc is : [] 132\n",
      "mathc is : [] 133\n",
      "mathc is : [] 134\n",
      "mathc is : ['n t '] 135\n",
      "mathc is : [] 136\n",
      "mathc is : [] 137\n",
      "mathc is : [] 138\n",
      "mathc is : [] 139\n",
      "mathc is : [] 140\n",
      "mathc is : [] 141\n",
      "mathc is : [] 142\n",
      "mathc is : [] 143\n",
      "mathc is : [] 144\n",
      "mathc is : [] 145\n",
      "mathc is : [] 146\n",
      "mathc is : [] 147\n",
      "mathc is : [] 148\n",
      "mathc is : [] 149\n",
      "mathc is : [] 150\n",
      "mathc is : [] 151\n",
      "mathc is : [] 152\n",
      "mathc is : [] 153\n",
      "mathc is : [] 154\n",
      "mathc is : [] 155\n",
      "mathc is : [] 156\n",
      "mathc is : [] 157\n",
      "mathc is : ['n t ', 'n t '] 158\n",
      "mathc is : [] 159\n",
      "mathc is : [] 160\n",
      "mathc is : [] 161\n",
      "mathc is : ['n t '] 162\n",
      "mathc is : [] 163\n",
      "mathc is : [] 164\n",
      "mathc is : [] 165\n",
      "mathc is : [] 166\n",
      "mathc is : [] 167\n",
      "mathc is : [] 168\n",
      "mathc is : [] 169\n",
      "mathc is : [] 170\n",
      "mathc is : [] 171\n",
      "mathc is : [] 172\n",
      "mathc is : [] 173\n",
      "mathc is : [] 174\n",
      "mathc is : [] 175\n",
      "mathc is : [] 176\n",
      "mathc is : [] 177\n",
      "mathc is : [] 178\n",
      "mathc is : [] 179\n",
      "mathc is : [] 180\n",
      "mathc is : [] 181\n",
      "mathc is : [] 182\n",
      "mathc is : [] 183\n",
      "mathc is : [] 184\n",
      "mathc is : [] 185\n",
      "mathc is : [] 186\n",
      "mathc is : [] 187\n",
      "mathc is : [] 188\n",
      "mathc is : [] 189\n",
      "mathc is : [] 190\n",
      "mathc is : [] 191\n",
      "mathc is : [] 192\n",
      "mathc is : [] 193\n",
      "mathc is : [] 194\n",
      "mathc is : [] 195\n",
      "mathc is : ['n t '] 196\n",
      "mathc is : [] 197\n",
      "mathc is : [] 198\n",
      "mathc is : [] 199\n",
      "mathc is : [] 200\n",
      "mathc is : [] 201\n",
      "mathc is : [] 202\n",
      "mathc is : ['n t ', 'n t ', 'n t '] 203\n",
      "mathc is : [] 204\n",
      "mathc is : [] 205\n",
      "mathc is : [] 206\n",
      "mathc is : [] 207\n",
      "mathc is : [] 208\n",
      "mathc is : [] 209\n",
      "mathc is : [] 210\n",
      "mathc is : [] 211\n",
      "mathc is : [] 212\n",
      "mathc is : [] 213\n",
      "mathc is : [] 214\n",
      "mathc is : [] 215\n",
      "mathc is : [] 216\n",
      "mathc is : [] 217\n",
      "mathc is : [] 218\n",
      "mathc is : [] 219\n",
      "mathc is : [] 220\n",
      "mathc is : [] 221\n",
      "mathc is : [] 222\n",
      "mathc is : [] 223\n",
      "mathc is : [] 224\n",
      "mathc is : [] 225\n",
      "mathc is : [] 226\n",
      "mathc is : [] 227\n",
      "mathc is : [] 228\n",
      "mathc is : [] 229\n",
      "mathc is : [] 230\n",
      "mathc is : [] 231\n",
      "mathc is : [] 232\n",
      "mathc is : [] 233\n",
      "mathc is : [] 234\n",
      "mathc is : [] 235\n",
      "mathc is : [] 236\n",
      "mathc is : [] 237\n",
      "mathc is : [] 238\n",
      "mathc is : [] 239\n",
      "mathc is : [] 240\n",
      "mathc is : [] 241\n",
      "mathc is : [] 242\n",
      "mathc is : [] 243\n",
      "mathc is : [] 244\n",
      "mathc is : [] 245\n",
      "mathc is : [] 246\n",
      "mathc is : [] 247\n",
      "mathc is : [] 248\n",
      "mathc is : [] 249\n",
      "mathc is : [] 250\n",
      "mathc is : [] 251\n",
      "mathc is : [] 252\n",
      "mathc is : [] 253\n",
      "mathc is : [] 254\n",
      "mathc is : [] 255\n",
      "mathc is : [] 256\n",
      "mathc is : [] 257\n",
      "mathc is : [] 258\n",
      "mathc is : [] 259\n",
      "mathc is : [] 260\n",
      "mathc is : [] 261\n",
      "mathc is : [] 262\n",
      "mathc is : [] 263\n",
      "mathc is : [] 264\n",
      "mathc is : [] 265\n",
      "mathc is : [] 266\n",
      "mathc is : [] 267\n",
      "mathc is : [] 268\n",
      "mathc is : [] 269\n",
      "mathc is : ['n t '] 270\n",
      "mathc is : [] 271\n",
      "mathc is : [] 272\n",
      "mathc is : [] 273\n",
      "mathc is : [] 274\n",
      "mathc is : [] 275\n",
      "mathc is : [] 276\n",
      "mathc is : [] 277\n",
      "mathc is : [] 278\n",
      "mathc is : [] 279\n",
      "mathc is : [] 280\n",
      "mathc is : [] 281\n",
      "mathc is : [] 282\n",
      "mathc is : [] 283\n",
      "mathc is : [] 284\n",
      "mathc is : [] 285\n",
      "mathc is : [] 286\n",
      "mathc is : [] 287\n",
      "mathc is : [] 288\n",
      "mathc is : [] 289\n",
      "mathc is : [] 290\n",
      "mathc is : ['n t '] 291\n",
      "mathc is : [] 292\n",
      "mathc is : [] 293\n",
      "mathc is : [] 294\n",
      "mathc is : [] 295\n",
      "mathc is : [] 296\n",
      "mathc is : [] 297\n",
      "mathc is : [] 298\n",
      "mathc is : ['n t '] 299\n",
      "mathc is : [] 300\n",
      "mathc is : [] 301\n",
      "mathc is : [] 302\n",
      "mathc is : [] 303\n",
      "mathc is : [] 304\n",
      "mathc is : [] 305\n",
      "mathc is : [] 306\n",
      "mathc is : [] 307\n",
      "mathc is : [] 308\n",
      "mathc is : [] 309\n",
      "mathc is : [] 310\n",
      "mathc is : ['n t '] 311\n",
      "mathc is : [] 312\n",
      "mathc is : [] 313\n",
      "mathc is : [] 314\n",
      "mathc is : [] 315\n",
      "mathc is : [] 316\n",
      "mathc is : [] 317\n",
      "mathc is : [] 318\n",
      "mathc is : [] 319\n",
      "mathc is : [] 320\n",
      "mathc is : [] 321\n",
      "mathc is : [] 322\n",
      "mathc is : [] 323\n",
      "mathc is : [] 324\n",
      "mathc is : [] 325\n",
      "mathc is : [] 326\n",
      "mathc is : [] 327\n",
      "mathc is : [] 328\n",
      "mathc is : [] 329\n",
      "mathc is : [] 330\n",
      "mathc is : [] 331\n",
      "mathc is : [] 332\n",
      "mathc is : [] 333\n",
      "mathc is : [] 334\n",
      "mathc is : [] 335\n",
      "mathc is : [] 336\n",
      "mathc is : [] 337\n",
      "mathc is : [] 338\n",
      "mathc is : [] 339\n",
      "mathc is : [] 340\n",
      "mathc is : [] 341\n",
      "mathc is : [] 342\n",
      "mathc is : [] 343\n",
      "mathc is : [] 344\n",
      "mathc is : [] 345\n",
      "mathc is : [] 346\n",
      "mathc is : [] 347\n",
      "mathc is : [] 348\n",
      "mathc is : [] 349\n",
      "mathc is : [] 350\n",
      "mathc is : [] 351\n",
      "mathc is : [] 352\n",
      "mathc is : [] 353\n",
      "mathc is : [] 354\n",
      "mathc is : [] 355\n",
      "mathc is : [] 356\n",
      "mathc is : [] 357\n",
      "mathc is : [] 358\n",
      "mathc is : [] 359\n",
      "mathc is : [] 360\n",
      "mathc is : [] 361\n",
      "mathc is : [] 362\n",
      "mathc is : [] 363\n",
      "mathc is : [] 364\n",
      "mathc is : [] 365\n",
      "mathc is : [] 366\n",
      "mathc is : ['n t '] 367\n",
      "mathc is : [] 368\n",
      "mathc is : [] 369\n",
      "mathc is : [] 370\n",
      "mathc is : [] 371\n",
      "mathc is : [] 372\n",
      "mathc is : [] 373\n",
      "mathc is : [] 374\n",
      "mathc is : [] 375\n",
      "mathc is : [] 376\n",
      "mathc is : [] 377\n",
      "mathc is : [] 378\n",
      "mathc is : ['n t '] 379\n",
      "mathc is : [] 380\n",
      "mathc is : [] 381\n",
      "mathc is : [] 382\n",
      "mathc is : [] 383\n",
      "mathc is : [] 384\n",
      "mathc is : [] 385\n",
      "mathc is : [] 386\n",
      "mathc is : [] 387\n",
      "mathc is : [] 388\n",
      "mathc is : [] 389\n",
      "mathc is : [] 390\n",
      "mathc is : [] 391\n",
      "mathc is : [] 392\n",
      "mathc is : [] 393\n",
      "mathc is : [] 394\n",
      "mathc is : [] 395\n",
      "mathc is : [] 396\n",
      "mathc is : [] 397\n",
      "mathc is : [] 398\n",
      "mathc is : [] 399\n",
      "mathc is : [] 400\n",
      "mathc is : [] 401\n",
      "mathc is : ['n t ', 'n t '] 402\n",
      "mathc is : [] 403\n",
      "mathc is : [] 404\n",
      "mathc is : [] 405\n",
      "mathc is : ['n t '] 406\n",
      "mathc is : [] 407\n",
      "mathc is : [] 408\n",
      "mathc is : [] 409\n",
      "mathc is : [] 410\n",
      "mathc is : [] 411\n",
      "mathc is : [] 412\n",
      "mathc is : [] 413\n",
      "mathc is : [] 414\n",
      "mathc is : [] 415\n",
      "mathc is : [] 416\n",
      "mathc is : [] 417\n",
      "mathc is : [] 418\n",
      "mathc is : [] 419\n",
      "mathc is : [] 420\n",
      "mathc is : [] 421\n",
      "mathc is : [] 422\n",
      "mathc is : [] 423\n",
      "mathc is : [] 424\n",
      "mathc is : [] 425\n",
      "mathc is : [] 426\n",
      "mathc is : [] 427\n",
      "mathc is : [] 428\n",
      "mathc is : [] 429\n",
      "mathc is : [] 430\n",
      "mathc is : [] 431\n",
      "mathc is : [] 432\n",
      "mathc is : [] 433\n",
      "mathc is : [] 434\n",
      "mathc is : [] 435\n",
      "mathc is : [] 436\n",
      "mathc is : [] 437\n",
      "mathc is : [] 438\n",
      "mathc is : [] 439\n",
      "mathc is : ['n t '] 440\n",
      "mathc is : [] 441\n",
      "mathc is : [] 442\n",
      "mathc is : [] 443\n",
      "mathc is : [] 444\n",
      "mathc is : [] 445\n",
      "mathc is : [] 446\n",
      "mathc is : ['n t ', 'n t '] 447\n",
      "mathc is : [] 448\n",
      "mathc is : [] 449\n",
      "mathc is : [] 450\n",
      "mathc is : [] 451\n",
      "mathc is : [] 452\n",
      "mathc is : [] 453\n",
      "mathc is : [] 454\n",
      "mathc is : [] 455\n",
      "mathc is : [] 456\n",
      "mathc is : [] 457\n",
      "mathc is : [] 458\n",
      "mathc is : [] 459\n",
      "mathc is : [] 460\n",
      "mathc is : [] 461\n",
      "mathc is : [] 462\n",
      "mathc is : [] 463\n",
      "mathc is : [] 464\n",
      "mathc is : [] 465\n",
      "mathc is : [] 466\n",
      "mathc is : [] 467\n",
      "mathc is : [] 468\n",
      "mathc is : [] 469\n",
      "mathc is : [] 470\n",
      "mathc is : [] 471\n",
      "mathc is : [] 472\n",
      "mathc is : [] 473\n",
      "mathc is : [] 474\n",
      "mathc is : [] 475\n",
      "mathc is : [] 476\n",
      "mathc is : [] 477\n",
      "mathc is : [] 478\n",
      "mathc is : [] 479\n",
      "mathc is : [] 480\n",
      "mathc is : [] 481\n",
      "mathc is : [] 482\n",
      "mathc is : [] 483\n",
      "mathc is : [] 484\n",
      "mathc is : [] 485\n",
      "mathc is : [] 486\n",
      "mathc is : [] 487\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,488):\n",
    "    matches = re.findall(\"n t \",corpus[i])\n",
    "    print(f'mathc is : {matches}', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good',\n",
       " 'afternoon',\n",
       " 'this',\n",
       " 'customer',\n",
       " 'be',\n",
       " 'be',\n",
       " 'charge',\n",
       " 'for',\n",
       " 'delivery',\n",
       " 'after',\n",
       " 'purchase',\n",
       " 'the',\n",
       " 'subscription',\n",
       " 'please',\n",
       " 'can',\n",
       " '-PRON-',\n",
       " 'see',\n",
       " 'if',\n",
       " '-PRON-',\n",
       " 'need',\n",
       " 'activate',\n",
       " 'thank',\n",
       " '-PRON-',\n",
       " 'in',\n",
       " 'advance',\n",
       " 'rebecca',\n",
       " 'connolly',\n",
       " 'proactive',\n",
       " 'notification',\n",
       " 'team']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemm=[]\n",
    "#for snt in corpus[0]:\n",
    "kr = nlp(corpus[0])\n",
    "for token in kr:\n",
    "    ls = token.lemma_\n",
    "    lemm.append(ls)\n",
    "lemm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.42625  ,  0.4431   , -0.34517  , -0.1326   , -0.05816  ,\n",
       "        0.052598 ,  0.21575  , -0.36721  , -0.04519  ,  2.2444   ,\n",
       "       -0.29089  ,  0.1667   , -0.052051 ,  0.15964  , -0.42759  ,\n",
       "       -0.11147  , -0.14951  ,  1.18     , -0.19603  ,  0.15592  ,\n",
       "       -0.06112  , -0.011576 ,  0.26849  , -0.30175  , -0.055796 ,\n",
       "        0.12116  ,  0.010542 , -0.18065  ,  0.23281  , -0.26367  ,\n",
       "        0.11032  ,  0.06216  ,  0.015019 , -0.10687  ,  0.098486 ,\n",
       "        0.048457 ,  0.33355  , -0.16177  , -0.28503  , -0.28655  ,\n",
       "       -0.11245  ,  0.12417  , -0.24975  , -0.2008   ,  0.26034  ,\n",
       "        0.25208  , -0.17841  ,  0.15395  , -0.19799  , -0.22644  ,\n",
       "       -0.074088 ,  0.50289  ,  0.32105  , -0.034766 ,  0.16543  ,\n",
       "        0.057095 , -0.20973  ,  0.098376 ,  0.035058 , -0.023057 ,\n",
       "       -0.11736  , -0.51327  , -0.020999 ,  0.39962  ,  0.30533  ,\n",
       "       -0.38839  ,  0.0026097,  0.29022  ,  0.017045 ,  0.063961 ,\n",
       "        0.10789  ,  0.29013  ,  0.061732 ,  0.068231 , -0.014031 ,\n",
       "        0.048649 , -0.011663 , -0.26527  , -0.14494  ,  0.45397  ,\n",
       "        0.067191 ,  0.14195  ,  0.37302  , -0.0076579,  0.018443 ,\n",
       "       -0.10224  , -0.0051647, -0.12233  ,  0.25855  , -0.11212  ,\n",
       "       -0.053952 , -0.19947  , -0.32291  ,  0.26205  ,  0.35758  ,\n",
       "       -0.2607   ,  0.37932  , -0.4268   ,  0.061313 ,  0.0085055,\n",
       "       -0.31061  , -0.15091  , -0.22569  ,  0.074085 ,  0.26419  ,\n",
       "       -0.9689   ,  0.3205   ,  0.013197 ,  0.020656 , -0.24059  ,\n",
       "        0.21454  , -0.38931  , -0.058037 , -0.055826 ,  0.22324  ,\n",
       "        0.18331  , -0.024247 , -0.1512   , -0.010921 , -0.27556  ,\n",
       "        0.31151  ,  0.21918  , -0.091469 ,  0.055151 ,  0.0064999,\n",
       "        0.13427  , -0.28369  , -0.38306  ,  0.073976 , -0.061432 ,\n",
       "        0.11585  , -0.093184 , -0.09172  , -0.22746  , -0.11907  ,\n",
       "        0.21006  ,  0.0097736, -0.23443  ,  0.29533  , -0.26389  ,\n",
       "       -2.1549   ,  0.391    ,  0.60844  ,  0.021372 , -0.29117  ,\n",
       "       -0.52578  , -0.30445  , -0.12788  ,  0.39592  ,  0.20246  ,\n",
       "       -0.38065  , -0.076001 ,  0.046315 , -0.24566  ,  0.014438 ,\n",
       "       -0.0095246, -0.029197 , -0.11232  , -0.029992 , -0.52387  ,\n",
       "        0.05365  ,  0.032134 ,  0.35621  ,  0.040588 ,  0.28366  ,\n",
       "       -0.51086  ,  0.20677  , -0.3715   ,  0.19042  , -0.048069 ,\n",
       "        0.0025944, -0.069552 ,  0.20583  , -0.40107  ,  0.0066834,\n",
       "        0.066419 , -0.19584  ,  0.19296  ,  0.14749  , -0.0423   ,\n",
       "       -0.044897 , -0.46937  , -0.38399  ,  0.019192 , -0.24857  ,\n",
       "       -0.14294  , -0.085374 , -0.088101 ,  0.23245  , -0.16668  ,\n",
       "       -0.025019 , -0.029291 , -0.0046514, -0.12139  , -0.20833  ,\n",
       "        0.24371  ,  0.060033 , -0.18485  ,  0.33876  ,  0.058523 ,\n",
       "        0.11933  ,  0.066886 , -0.20035  , -0.054426 ,  0.03731  ,\n",
       "        0.22031  , -0.22824  ,  0.048875 ,  0.060931 ,  0.026946 ,\n",
       "       -0.20081  , -0.005543 ,  0.043733 , -0.60604  , -0.20841  ,\n",
       "        0.13012  ,  0.18033  , -0.086796 , -0.13199  ,  0.05757  ,\n",
       "       -0.161    , -0.07107  ,  0.015812 ,  0.40779  ,  0.53949  ,\n",
       "        0.13829  , -0.20688  ,  0.076653 ,  0.097948 ,  0.071683 ,\n",
       "       -0.10647  ,  0.054176 , -0.2932   ,  0.14681  ,  0.16784  ,\n",
       "       -0.20442  ,  0.047034 , -0.31862  , -0.2226   ,  0.12788  ,\n",
       "        0.17326  , -0.10272  , -0.15957  ,  0.25465  ,  0.27582  ,\n",
       "        0.011341 , -0.21905  , -0.50156  , -0.15053  ,  0.098795 ,\n",
       "        0.31615  , -0.087923 , -0.48265  , -0.1241   , -0.11466  ,\n",
       "        0.22522  ,  0.28101  , -0.38343  , -0.19752  ,  0.067079 ,\n",
       "       -0.1339   ,  0.1416   ,  0.26925  ,  0.42701  ,  0.1372   ,\n",
       "       -0.13302  ,  0.13731  ,  0.32494  ,  0.55031  ,  0.25321  ,\n",
       "        0.077384 ,  0.049114 , -0.36115  , -0.52553  , -0.37361  ,\n",
       "        0.36655  ,  0.032056 , -0.28452  ,  0.14393  ,  0.70665  ,\n",
       "       -0.2256   , -0.2962   , -0.18957  , -0.04505  , -0.023948 ,\n",
       "        0.078238 ,  0.08545  , -0.23747  ,  0.17435  ,  0.039811 ,\n",
       "       -0.45907  , -0.052783 , -0.32051  , -0.12172  ,  0.31545  ,\n",
       "        0.045489 ,  0.22644  , -0.4303   , -0.068851 ,  0.12875  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(lemm[0]).vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
